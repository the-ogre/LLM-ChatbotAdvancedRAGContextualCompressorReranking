{"metadata":{"environment":{"kernel":"python3","name":"common-gpu.m114","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-gpu:m114"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7269765,"sourceType":"datasetVersion","datasetId":4214145},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3900}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:30:40.022166Z","iopub.execute_input":"2024-01-02T12:30:40.023064Z","iopub.status.idle":"2024-01-02T12:30:41.037904Z","shell.execute_reply.started":"2024-01-02T12:30:40.023026Z","shell.execute_reply":"2024-01-02T12:30:41.036724Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:30:44.369310Z","iopub.execute_input":"2024-01-02T12:30:44.369769Z","iopub.status.idle":"2024-01-02T12:30:44.374773Z","shell.execute_reply.started":"2024-01-02T12:30:44.369731Z","shell.execute_reply":"2024-01-02T12:30:44.373805Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:24:29.001388Z","iopub.execute_input":"2024-01-02T12:24:29.001784Z","iopub.status.idle":"2024-01-02T12:24:29.006396Z","shell.execute_reply.started":"2024-01-02T12:24:29.001756Z","shell.execute_reply":"2024-01-02T12:24:29.005443Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !pip install torch --index-url https://download.pytorch.org/whl/cu118\n# !pip install -qU langchain cohere tiktoken pypdf sentence_transformers faiss-gpu peft bitsandbytes trl\n# !pip install -q accelerate==0.21.0","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:26:17.983699Z","iopub.execute_input":"2024-01-02T12:26:17.984074Z","iopub.status.idle":"2024-01-02T12:26:17.988807Z","shell.execute_reply.started":"2024-01-02T12:26:17.984039Z","shell.execute_reply":"2024-01-02T12:26:17.987768Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nfrom getpass import getpass\nos.environ[\"COHERE_API_KEY\"] = getpass(\"Cohere API Key:\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:20:15.482087Z","iopub.execute_input":"2024-01-02T13:20:15.482482Z","iopub.status.idle":"2024-01-02T13:20:45.191947Z","shell.execute_reply.started":"2024-01-02T13:20:15.482449Z","shell.execute_reply":"2024-01-02T13:20:45.190966Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdin","text":"Cohere API Key: ········································\n"}]},{"cell_type":"code","source":"from langchain.document_loaders.pdf import PyPDFDirectoryLoader\npdf_folder_path = \"/kaggle/input/nlp-book-set\"\nloader = PyPDFDirectoryLoader(pdf_folder_path)\ndocs = loader.load()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:26:50.037260Z","iopub.execute_input":"2024-01-02T12:26:50.038207Z","iopub.status.idle":"2024-01-02T12:27:31.517989Z","shell.execute_reply.started":"2024-01-02T12:26:50.038171Z","shell.execute_reply":"2024-01-02T12:27:31.517182Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### SPLIT THE DOCUMENTS","metadata":{}},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\ntexts = text_splitter.split_documents(docs)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:28:51.490830Z","iopub.execute_input":"2024-01-02T12:28:51.491512Z","iopub.status.idle":"2024-01-02T12:28:51.744683Z","shell.execute_reply.started":"2024-01-02T12:28:51.491477Z","shell.execute_reply":"2024-01-02T12:28:51.743752Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(len(texts))","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:29:19.825648Z","iopub.execute_input":"2024-01-02T12:29:19.826273Z","iopub.status.idle":"2024-01-02T12:29:19.830832Z","shell.execute_reply.started":"2024-01-02T12:29:19.826241Z","shell.execute_reply":"2024-01-02T12:29:19.829923Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"5054\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DEFINE EMBEDDING MODEL","metadata":{}},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceBgeEmbeddings\nmodel_name = \"BAAI/bge-large-en-v1.5\"\nmodel_kwargs = {'device': 'cuda'}\nencode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\nembeddings = HuggingFaceBgeEmbeddings(\n    model_name=model_name,\n    model_kwargs=model_kwargs,\n    encode_kwargs=encode_kwargs\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:47:14.241233Z","iopub.execute_input":"2024-01-02T12:47:14.241597Z","iopub.status.idle":"2024-01-02T12:47:14.957718Z","shell.execute_reply.started":"2024-01-02T12:47:14.241570Z","shell.execute_reply":"2024-01-02T12:47:14.956635Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### BASE VECTOR STORE (FAISS) RETRIEVER","metadata":{}},{"cell_type":"code","source":"from langchain.vectorstores import FAISS\nvectorstore = FAISS.from_documents(texts, embeddings)\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})","metadata":{"execution":{"iopub.status.busy":"2024-01-02T12:47:18.050857Z","iopub.execute_input":"2024-01-02T12:47:18.051254Z","iopub.status.idle":"2024-01-02T12:50:07.317965Z","shell.execute_reply.started":"2024-01-02T12:47:18.051221Z","shell.execute_reply":"2024-01-02T12:50:07.316910Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/158 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74c5c11a1d32464c8c311350cd749c18"}},"metadata":{}}]},{"cell_type":"markdown","source":"### RERANKING WITH COHERE RERANK","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import CohereRerank","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:05.943455Z","iopub.execute_input":"2024-01-02T13:21:05.943837Z","iopub.status.idle":"2024-01-02T13:21:05.948876Z","shell.execute_reply.started":"2024-01-02T13:21:05.943807Z","shell.execute_reply":"2024-01-02T13:21:05.947931Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"compressor = CohereRerank()\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor, \n    base_retriever=retriever\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:07.592201Z","iopub.execute_input":"2024-01-02T13:21:07.592554Z","iopub.status.idle":"2024-01-02T13:21:07.597343Z","shell.execute_reply.started":"2024-01-02T13:21:07.592525Z","shell.execute_reply":"2024-01-02T13:21:07.596402Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### OPENAI MODEL","metadata":{}},{"cell_type":"code","source":"#!pip install pydantic==1.10.9 openai==0.27.8","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:19:42.134919Z","iopub.execute_input":"2024-01-02T13:19:42.135540Z","iopub.status.idle":"2024-01-02T13:19:42.140998Z","shell.execute_reply.started":"2024-01-02T13:19:42.135486Z","shell.execute_reply":"2024-01-02T13:19:42.139916Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import openai\nfrom langchain.chat_models import ChatOpenAI","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:11.348592Z","iopub.execute_input":"2024-01-02T13:21:11.348942Z","iopub.status.idle":"2024-01-02T13:21:11.353273Z","shell.execute_reply.started":"2024-01-02T13:21:11.348917Z","shell.execute_reply":"2024-01-02T13:21:11.352312Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"os.environ['OPENAI_API_KEY'] = \"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\"\nmodel_name = \"gpt-3.5-turbo\"\nllm = ChatOpenAI(model_name=model_name)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:13.602126Z","iopub.execute_input":"2024-01-02T13:21:13.602545Z","iopub.status.idle":"2024-01-02T13:21:13.610562Z","shell.execute_reply.started":"2024-01-02T13:21:13.602510Z","shell.execute_reply":"2024-01-02T13:21:13.609408Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"### RAG PIPELINE WITH COMPRESSOR RETRIEVER","metadata":{}},{"cell_type":"code","source":"from langchain.chains import RetrievalQA","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:17.141450Z","iopub.execute_input":"2024-01-02T13:21:17.142306Z","iopub.status.idle":"2024-01-02T13:21:17.146643Z","shell.execute_reply.started":"2024-01-02T13:21:17.142269Z","shell.execute_reply":"2024-01-02T13:21:17.145627Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"rag_pipeline = RetrievalQA.from_chain_type(llm=llm,\n                                 chain_type=\"stuff\",\n                                 retriever=compression_retriever)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:19.066395Z","iopub.execute_input":"2024-01-02T13:21:19.067274Z","iopub.status.idle":"2024-01-02T13:21:19.072270Z","shell.execute_reply.started":"2024-01-02T13:21:19.067242Z","shell.execute_reply":"2024-01-02T13:21:19.071302Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"query = \"Tell me about various advanced Retrieval Systems\"\nprint(rag_pipeline.run(query=query))","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:21.384870Z","iopub.execute_input":"2024-01-02T13:21:21.385608Z","iopub.status.idle":"2024-01-02T13:21:34.869580Z","shell.execute_reply.started":"2024-01-02T13:21:21.385573Z","shell.execute_reply":"2024-01-02T13:21:34.868494Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c3dd8b495a749c3a91446c1b9dfd50c"}},"metadata":{}},{"name":"stdout","text":"There are various advanced retrieval systems used in information retrieval and natural language processing. Some of these systems include:\n\n1. Ranking-based Retrieval Systems: These systems rank the retrieved documents based on their relevance to the query. They use different ranking algorithms and techniques to determine the importance of each document.\n\n2. Neural Network-based Retrieval Systems: These systems use artificial neural networks to learn the semantic relationships between queries and documents. They can capture complex patterns and representations in the data, leading to more accurate retrieval results.\n\n3. Knowledge Graph-based Retrieval Systems: These systems utilize knowledge graphs, which are structured representations of knowledge, to enhance retrieval. They leverage the relationships and connections within the knowledge graph to improve the relevance of the retrieved documents.\n\n4. Personalized Retrieval Systems: These systems take into account the user's preferences, history, and behavior to provide personalized search results. They use techniques like collaborative filtering and content-based filtering to recommend documents that are more relevant and interesting to the user.\n\n5. Context-aware Retrieval Systems: These systems consider the context in which the retrieval is performed, such as the user's location, time, and device. By incorporating contextual information, they can provide more tailored and relevant search results.\n\n6. Multi-modal Retrieval Systems: These systems retrieve information from multiple modalities, such as text, images, and videos. They aim to provide a more comprehensive and holistic retrieval experience by considering different types of content.\n\nThese are just a few examples of advanced retrieval systems. The field of information retrieval is constantly evolving, and researchers are continuously exploring new techniques to improve the effectiveness and efficiency of retrieval systems.\n","output_type":"stream"}]},{"cell_type":"code","source":"query_set = [\n    \"How does LLMs learn\",\n    \"Write a short history of NLP from 2000 to 2023\",\n    \"Write a code that explain a symple Speech recognition\",\n    \"What is coreference solution?\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:50.754271Z","iopub.execute_input":"2024-01-02T13:21:50.754668Z","iopub.status.idle":"2024-01-02T13:21:50.759313Z","shell.execute_reply.started":"2024-01-02T13:21:50.754636Z","shell.execute_reply":"2024-01-02T13:21:50.758325Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"for query in query_set:\n    print(rag_pipeline.run(query))","metadata":{"execution":{"iopub.status.busy":"2024-01-02T13:21:58.271416Z","iopub.execute_input":"2024-01-02T13:21:58.271807Z","iopub.status.idle":"2024-01-02T13:22:46.794566Z","shell.execute_reply.started":"2024-01-02T13:21:58.271778Z","shell.execute_reply":"2024-01-02T13:22:46.793412Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3f7c1df041b463f980d847c5378c597"}},"metadata":{}},{"name":"stdout","text":"LLMs (Language Models) learn by analyzing large amounts of text data and predicting the likelihood of a word or sequence of words occurring in a given context. They are trained using a process called Masked Language Modeling (MLM), where words in a sentence are randomly masked, and the model is tasked with predicting the masked words based on the surrounding context.\n\nDuring training, the LLM is presented with a series of sentences where some words are masked. It then learns to predict the masked words by considering the context provided by the surrounding words. The model is trained to assign higher probabilities to words that are more likely to appear in a given context.\n\nThe training process involves adjusting the parameters of the LLM based on the error between the predicted probabilities and the actual words. This is done through backpropagation and gradient descent, where the model iteratively updates its parameters to improve its predictions.\n\nBy analyzing a large corpus of text and repeatedly predicting and adjusting its parameters, the LLM learns the statistical patterns and relationships between words, allowing it to generate coherent and contextually appropriate text.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60f6cd265e014fb6b1bda7c2d6f28e1f"}},"metadata":{}},{"name":"stdout","text":"From 2000 to 2023, Natural Language Processing (NLP) has made significant advancements and witnessed remarkable growth. Various developments and breakthroughs have shaped the field during this period.\n\nIn the early 2000s, researchers focused on core areas of NLP, such as syntactic parsing, semantic analysis, and named entity recognition. They explored rule-based approaches and statistical models to improve the accuracy of these tasks. Researchers also worked on building large annotated datasets to train machine learning models.\n\nAround 2006, there was a shift towards utilizing more data-driven approaches in NLP. This led to the rise of machine learning techniques, including supervised, unsupervised, and semi-supervised learning. Researchers started using large-scale datasets and more complex models, such as neural networks, to achieve better performance in various NLP tasks.\n\nIn the following years, there was a surge in research related to specific NLP tasks, such as sentiment analysis, information extraction, and question-answering systems. Researchers explored different methods, including deep learning, to improve the accuracy and efficiency of these tasks.\n\nThe period between 2010 and 2020 witnessed significant advancements in NLP fueled by the availability of large-scale datasets and the rise of deep learning. Models like Recurrent Neural Networks (RNNs) and Transformers revolutionized the field by achieving state-of-the-art performance in tasks like machine translation, text generation, and language understanding.\n\nIn recent years, there has been a growing focus on ethical considerations and bias in NLP. Researchers have started addressing issues related to fairness, transparency, and accountability in NLP models and datasets. This has led to the development of guidelines and frameworks to mitigate bias and ensure responsible use of NLP technologies.\n\nAs of 2023, NLP continues to evolve rapidly. Ongoing research involves exploring multimodal NLP, which combines text with other modalities like images and audio. Additionally, there is a growing interest in explainability and interpretability of NLP models, aiming to make them more transparent and understandable to users.\n\nOverall, the history of NLP from 2000 to 2023 has been characterized by the integration of machine learning techniques, the development of large-scale datasets, and a focus on improving the performance and ethical considerations of NLP systems.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b5e780535a4ced9e00f70134a04274"}},"metadata":{}},{"name":"stdout","text":"Certainly! Here's a simple example code that demonstrates speech recognition using the SpeechRecognition library in Python:\n\n```python\nimport speech_recognition as sr\n\n# Create a recognizer object\nrecognizer = sr.Recognizer()\n\n# Define the audio source (e.g., microphone)\nwith sr.Microphone() as source:\n    print(\"Listening...\")\n\n    # Adjust for ambient noise\n    recognizer.adjust_for_ambient_noise(source)\n\n    # Capture the audio input\n    audio = recognizer.listen(source)\n\n    try:\n        # Use the recognizer to convert speech to text\n        text = recognizer.recognize_google(audio)\n        print(\"You said:\", text)\n\n    except sr.UnknownValueError:\n        print(\"Oops! Unable to understand audio.\")\n\n    except sr.RequestError as e:\n        print(\"Oops! An error occurred.\", e)\n```\n\nIn this code, we first import the `speech_recognition` library. We create a recognizer object and define the audio source as the microphone. We then use the `adjust_for_ambient_noise` method to account for any background noise. Next, we capture the audio input using the `listen` method.\n\nInside a try-except block, we use the `recognize_google` method to convert the captured audio into text. If the recognition is successful, the recognized text is printed. If there is an unknown value error or a request error, appropriate error messages are displayed.\n\nNote that you need to install the SpeechRecognition library using `pip install SpeechRecognition` before running this code. Also, make sure you have a working microphone connected to your system.\n\nRemember to handle any exceptions and errors as per your application requirements. This code provides a basic starting point for speech recognition and can be expanded upon based on your specific needs.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3934b3038e4097b907773a104d4b4a"}},"metadata":{}},{"name":"stdout","text":"Coreference resolution is the task of linking together mentions in a text that refer to the same entity. It involves identifying and connecting pronouns, definite and indefinite noun phrases, and names that refer to the same entity in a discourse model. The goal is to create a set of coreference chains or clusters. Various approaches, such as machine learning, have been used to classify pairs of noun phrases as coreferring or not, based on annotated data. A separate clustering mechanism is then used to reconcile any conflicting classifications and create a partition of the noun phrases.\n","output_type":"stream"}]}]}